#!/bin/bash
set -euo pipefail

# Color codes
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() {
  echo -e "${GREEN}[$(date '+%Y-%m-%d %H:%M:%S')]${NC} INFO: $*"
}

log_error() {
  echo -e "${RED}[$(date '+%Y-%m-%d %H:%M:%S')]${NC} ERROR: $*" >&2
}

log_warn() {
  echo -e "${YELLOW}[$(date '+%Y-%m-%d %H:%M:%S')]${NC} WARN: $*"
}

log_section() {
  echo ""
  echo -e "${BLUE}====== $* ======${NC}"
}

# Performance thresholds based on Red Hat documentation
declare -A THRESHOLDS=(
  [fio_write_iops_min]=500
  [fio_write_latency_max]=10
  [fio_fsync_latency_max]=20
  [etcd_99_percentile_max]=50
  [etcd_wal_sync_max]=10
)

log_section "FIO Disk Performance Tests"

# Function to run FIO tests on a node
run_fio_test() {
  local node=$1
  local test_name=$2
  local fio_params=$3
  
  log_info "Running FIO test '$test_name' on $node..."
  
  local result=$(oc debug node/"$node" -- chroot /host bash -c "
    fio --directory=/var/lib/etcd \
        --name=$test_name \
        $fio_params \
        --output-format=json
  " 2>/dev/null)
  
  echo "$result" > "$results_dir/${node}_${test_name}.json"
  
  if [[ -z "$result" ]]; then
    log_error "FIO test failed on $node"
    return 1
  fi
  
  # Parse results
  local write_iops=$(echo "$result" | jq -r '.jobs[0].write.iops // 0' 2>/dev/null || echo "0")
  local write_lat=$(echo "$result" | jq -r '.jobs[0].write.lat_ns.mean // 0' 2>/dev/null || echo "0")
  local write_lat_ms=$(echo "scale=2; $write_lat / 1000000" | bc 2>/dev/null || echo "0")
  
  log_info "  Write IOPS: $write_iops"
  log_info "  Average write latency: ${write_lat_ms}ms"
  
  # Check thresholds
  if (( $(echo "$write_iops < ${THRESHOLDS[fio_write_iops_min]}" | bc -l) )); then
    log_warn "  Write IOPS below threshold (${THRESHOLDS[fio_write_iops_min]})"
  else
    log_info "  ✓ Write IOPS meets requirements"
  fi
  
  if (( $(echo "$write_lat_ms > ${THRESHOLDS[fio_write_latency_max]}" | bc -l) )); then
    log_warn "  Write latency above threshold (${THRESHOLDS[fio_write_latency_max]}ms)"
  else
    log_info "  ✓ Write latency meets requirements"
  fi
  
  return 0
}

# Run FIO tests on all master nodes
for node in "${master_nodes[@]}"; do
  log_info "Testing node: $node"
  
  # Test 1: Sequential write test
  run_fio_test "$node" "seq-write" \
    "--ioengine=libaio --direct=1 --bs=32k --size=1G --rw=write --numjobs=1 --time_based --runtime=60"
  
  # Test 2: Random write with fsync (simulates etcd workload)
  run_fio_test "$node" "rand-write-fsync" \
    "--ioengine=libaio --direct=1 --bs=2300 --size=1G --rw=randwrite --numjobs=1 --time_based --runtime=60 --fsync=1"
  
  # Test 3: Fsync latency test (critical for etcd)
  log_info "Running fsync latency test on $node..."
  fsync_result=$(oc debug node/"$node" -- chroot /host bash -c "
    cd /var/lib/etcd
    for i in {1..100}; do
      dd if=/dev/zero of=test_\$i bs=2300 count=1 conv=fsync 2>&1 | grep -oP '(?<=, )[0-9.]+ (?=s)'
    done | awk '{sum+=\$1; count++} END {print sum/count}'
    rm -f test_*
  " 2>/dev/null || echo "0")
  
  fsync_lat_ms=$(echo "scale=2; $fsync_result * 1000" | bc 2>/dev/null || echo "0")
  log_info "  Average fsync latency: ${fsync_lat_ms}ms"
  
  if (( $(echo "$fsync_lat_ms > ${THRESHOLDS[fio_fsync_latency_max]}" | bc -l) )); then
    log_warn "  Fsync latency above threshold (${THRESHOLDS[fio_fsync_latency_max]}ms)"
  else
    log_info "  ✓ Fsync latency meets requirements"
  fi
  
  echo ""
done

log_section "etcd-perf Benchmark Test"

# Alternative: Run etcd-perf from etcd pod directly
log_info "Running etcd performance check from etcd pod..."
etcd_pod=$(oc get pod -n openshift-etcd -l app=etcd -o name | head -1)

if [[ -z "$etcd_pod" ]]; then
  log_error "Could not find etcd pod"
else
  perf_result=$(oc exec -n openshift-etcd "$etcd_pod" -c etcd -- /bin/bash -c '
etcdctl check perf --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/etcd/ca/ca.crt \
  --cert=/etc/etcd/client/tls.crt \
  --key=/etc/etcd/client/tls.key
' 2>&1 || echo "perf check failed")

  echo "$perf_result" | tee "$results_dir/etcd_perf_check.txt"

  # Parse etcd perf results
  if echo "$perf_result" | grep -q "PASS"; then
    log_info "✓ etcd performance check PASSED"
  else
    log_warn "etcd performance check did not pass completely"
  fi
fi

log_section "etcd Metrics Analysis"

# Get etcd metrics
log_info "Collecting etcd metrics from Prometheus..."

# Helper function to query Prometheus
query_prometheus() {
  local query=$1
  local result=$(oc exec -n openshift-monitoring prometheus-k8s-0 -c prometheus -- \
    curl -s "http://localhost:9090/api/v1/query?query=${query}" 2>/dev/null | \
    jq -r '.data.result[0].value[1] // "N/A"' 2>/dev/null || echo "N/A")
  echo "$result"
}

log_info "Querying etcd performance metrics..."

# WAL fsync duration (99th percentile) - should be < 10ms
wal_fsync_99=$(query_prometheus 'histogram_quantile(0.99, rate(etcd_disk_wal_fsync_duration_seconds_bucket[5m]))')
wal_fsync_99_ms=$(echo "scale=2; $wal_fsync_99 * 1000" | bc 2>/dev/null || echo "N/A")
log_info "WAL fsync duration (99th): ${wal_fsync_99_ms}ms"

# Backend commit duration (99th percentile) - should be < 25ms
backend_commit_99=$(query_prometheus 'histogram_quantile(0.99, rate(etcd_disk_backend_commit_duration_seconds_bucket[5m]))')
backend_commit_99_ms=$(echo "scale=2; $backend_commit_99 * 1000" | bc 2>/dev/null || echo "N/A")
log_info "Backend commit duration (99th): ${backend_commit_99_ms}ms"

# Leader changes - should be 0 or very low
leader_changes=$(query_prometheus 'rate(etcd_server_leader_changes_seen_total[1h])')
log_info "Leader changes (per hour): $leader_changes"

# Apply duration (99th percentile) - should be < 50ms
apply_99=$(query_prometheus 'histogram_quantile(0.99, rate(etcd_request_duration_seconds_bucket{operation="apply"}[5m]))')
apply_99_ms=$(echo "scale=2; $apply_99 * 1000" | bc 2>/dev/null || echo "N/A")
log_info "Apply duration (99th): ${apply_99_ms}ms"

# DB size
db_size=$(query_prometheus 'etcd_mvcc_db_total_size_in_bytes')
db_size_mb=$(echo "scale=2; $db_size / 1024 / 1024" | bc 2>/dev/null || echo "N/A")
log_info "etcd database size: ${db_size_mb}MB"

# Save metrics
cat > "$results_dir/etcd_metrics.txt" <<METRICS
etcd Performance Metrics
========================
WAL fsync duration (99th): ${wal_fsync_99_ms}ms (threshold: <${THRESHOLDS[etcd_wal_sync_max]}ms)
Backend commit duration (99th): ${backend_commit_99_ms}ms (threshold: <25ms)
Apply duration (99th): ${apply_99_ms}ms (threshold: <${THRESHOLDS[etcd_99_percentile_max]}ms)
Leader changes (hourly): $leader_changes (should be 0)
Database size: ${db_size_mb}MB
METRICS

# Evaluate metrics against thresholds
log_info ""
log_info "Evaluating metrics against thresholds..."
all_passed=true

if [[ "$wal_fsync_99_ms" != "N/A" ]]; then
  if (( $(echo "$wal_fsync_99_ms > ${THRESHOLDS[etcd_wal_sync_max]}" | bc -l) )); then
    log_warn "✗ WAL fsync duration exceeds threshold"
    all_passed=false
  else
    log_info "✓ WAL fsync duration within acceptable range"
  fi
fi

if [[ "$apply_99_ms" != "N/A" ]]; then
  if (( $(echo "$apply_99_ms > ${THRESHOLDS[etcd_99_percentile_max]}" | bc -l) )); then
    log_warn "✗ Apply duration exceeds threshold"
    all_passed=false
  else
    log_info "✓ Apply duration within acceptable range"
  fi
fi

log_section "Disk I/O Statistics"

for node in "${master_nodes[@]}"; do
  log_info "Disk statistics for $node:"
  
  oc debug node/"$node" -- chroot /host bash -c '
    echo "=== Disk Usage ==="
    df -h /var/lib/etcd
    echo ""
    echo "=== I/O Statistics ==="
    iostat -x 1 3 | grep -A3 "Device"
  ' 2>/dev/null | tee "$results_dir/${node}_iostat.txt" || log_warn "Could not collect iostat for $node"
  
  echo ""
done

log_section "etcd Health Check"

# Check etcd cluster health
log_info "Checking etcd cluster health..."
health_output=$(oc exec -n openshift-etcd "$etcd_pod" -c etcd -- /bin/bash -c '
etcdctl endpoint health \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/etcd/ca/ca.crt \
  --cert=/etc/etcd/client/tls.crt \
  --key=/etc/etcd/client/tls.key \
  --cluster
' 2>&1)

echo "$health_output" | tee "$results_dir/etcd_health.txt"

if echo "$health_output" | grep -q "is healthy"; then
  log_info "✓ All etcd members are healthy"
else
  log_error "✗ Some etcd members are unhealthy"
  all_passed=false
fi

# Check etcd member list
log_info ""
log_info "etcd member list:"
oc exec -n openshift-etcd "$etcd_pod" -c etcd -- /bin/bash -c '
etcdctl member list -w table \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/etcd/ca/ca.crt \
  --cert=/etc/etcd/client/tls.crt \
  --key=/etc/etcd/client/tls.key
' 2>&1 | tee "$results_dir/etcd_members.txt"

log_section "Performance Summary Report"

# Generate summary report
cat > "$results_dir/SUMMARY_REPORT.txt" <<REPORT
etcd Performance Verification Report
=====================================
Date: $(date)
Cluster: $(oc whoami --show-server)

DISK PERFORMANCE (FIO Tests)
-----------------------------
$(for node in "${master_nodes[@]}"; do
  echo "Node: $node"
  if [[ -f "$results_dir/${node}_seq-write.json" ]]; then
    iops=$(jq -r '.jobs[0].write.iops // 0' "$results_dir/${node}_seq-write.json" 2>/dev/null)
    echo "  Sequential Write IOPS: $iops"
  fi
  if [[ -f "$results_dir/${node}_rand-write-fsync.json" ]]; then
    iops=$(jq -r '.jobs[0].write.iops // 0' "$results_dir/${node}_rand-write-fsync.json" 2>/dev/null)
    echo "  Random Write with fsync IOPS: $iops"
  fi
  echo ""
done)

ETCD METRICS
------------
WAL fsync duration (99th): ${wal_fsync_99_ms}ms (threshold: <${THRESHOLDS[etcd_wal_sync_max]}ms)
Backend commit duration (99th): ${backend_commit_99_ms}ms (threshold: <25ms)
Apply duration (99th): ${apply_99_ms}ms (threshold: <${THRESHOLDS[etcd_99_percentile_max]}ms)
Leader changes (hourly): $leader_changes
Database size: ${db_size_mb}MB

ETCD HEALTH
-----------
$(cat "$results_dir/etcd_health.txt" 2>/dev/null || echo "N/A")

OVERALL ASSESSMENT
------------------
REPORT

if [[ "$all_passed" == true ]]; then
  echo "STATUS: PASSED ✓" >> "$results_dir/SUMMARY_REPORT.txt"
  echo "All performance metrics meet requirements." >> "$results_dir/SUMMARY_REPORT.txt"
  log_info "${GREEN}✓ All performance checks PASSED${NC}"
else
  echo "STATUS: NEEDS ATTENTION ⚠" >> "$results_dir/SUMMARY_REPORT.txt"
  echo "Some metrics are outside acceptable thresholds. Review detailed logs." >> "$results_dir/SUMMARY_REPORT.txt"
  log_warn "${YELLOW}⚠ Some performance checks need attention${NC}"
fi

cat "$results_dir/SUMMARY_REPORT.txt"

log_section "Verification Complete"
log_info "Detailed results saved to: $results_dir"
log_info "Summary report: $results_dir/SUMMARY_REPORT.txt"
log_info ""
log_info "Next steps:"
log_info "  1. Review the summary report"
log_info "  2. Import Grafana dashboard for continuous monitoring"
log_info "  3. Run Prometheus query verification script"

exit 0etcd Performance Verification Script"
log_info "This script will:"
log_info "  1. Run FIO disk performance tests (Red Hat KB 4885641)"
log_info "  2. Run etcd-perf benchmark (Red Hat KB 6271341)"
log_info "  3. Check etcd metrics and health"
log_info "  4. Generate performance report"
echo ""

# Get master nodes
log_info "Retrieving master node information..."
master_nodes=($(oc get nodes -l node-role.kubernetes.io/master= -o jsonpath='{.items[*].metadata.name}'))

if [[ ${#master_nodes[@]} -ne 3 ]]; then
  log_error "Expected 3 master nodes, found ${#master_nodes[@]}"
  exit 1
fi

log_info "Master nodes: ${master_nodes[*]}"

# Results storage
results_dir="/tmp/etcd-perf-results-$(date +%Y%m%d-%H%M%S)"
mkdir -p "$results_dir"
log_info "Results will be saved to: $results_dir"

log_section "
