4. Define Example Manifests for Lifecycle Policy

We will use Crossplane to define Azure Storage Account and lifecycle policy.

Create an Azure Provider in ArgoCD
Install Crossplane:
kubectl apply -f https://raw.githubusercontent.com/crossplane/crossplane/master/docs/install-crossplane.yaml
Install the Azure Provider:
kubectl apply -f - <<EOF
apiVersion: pkg.crossplane.io/v1
kind: Provider
metadata:
  name: crossplane-provider-azure
spec:
  package: xpkg.upbound.io/upbound/provider-azure
EOF
Storage Account Container (logs-container.yaml)
Define a container inside an existing Azure Storage Account:

apiVersion: storage.azure.upbound.io/v1beta1
kind: Container
metadata:
  name: logs-container
  namespace: openshift-gitops
spec:
  forProvider:
    storageAccountName: <STORAGE_ACCOUNT_NAME>
    resourceGroupName: <RESOURCE_GROUP>
    containerAccessType: private
  providerConfigRef:
    name: azure-config
Lifecycle Policy (lifecycle-policy.yaml)
Define a 90-day auto-delete policy for blobs inside the logs container:

apiVersion: storage.azure.upbound.io/v1beta1
kind: ManagementPolicy
metadata:
  name: logs-lifecycle-policy
  namespace: openshift-gitops
spec:
  forProvider:
    storageAccountName: <STORAGE_ACCOUNT_NAME>
    resourceGroupName: <RESOURCE_GROUP>
    rules:
      - name: DeleteBlobsAfter90Days
        enabled: true
        type: Lifecycle
        definition:
          actions:
            delete:
              daysAfterModificationGreaterThan: 90
          filters:
            blobTypes:
              - blockBlob
  providerConfigRef:
    name: azure-config
Kustomization.yaml
Combine all configurations:

apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - resource-group1/logs-container.yaml
  - resource-group1/lifecycle-policy.yaml
  - resource-group2/logs-container.yaml
  - resource-group2/lifecycle-policy.yaml
5. Configure ArgoCD to Apply the Policies

Define an ArgoCD Application to sync the GitOps repository.

apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: azure-storage-gitops
  namespace: openshift-gitops
spec:
  project: default
  source:
    repoURL: https://github.com/<your-org>/azure-gitops.git
    targetRevision: main
    path: storage
  destination:
    server: https://kubernetes.default.svc
    namespace: openshift-gitops
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
Apply the Application to ArgoCD
oc apply -f storage-app.yaml
This will trigger ArgoCD to deploy Azure storage configurations.







1. Define the Lifecycle Management Policy
Create a manifest to only apply the lifecycle policy to the existing container:

apiVersion: storage.azure.upbound.io/v1beta1
kind: ManagementPolicy
metadata:
  name: log-storage-lifecycle-policy
  namespace: openshift-gitops
spec:
  forProvider:
    storageAccountName: <STORAGE_ACCOUNT_NAME>  # Existing storage account
    resourceGroupName: <RESOURCE_GROUP>        # Existing resource group
    rules:
      - name: DeleteBlobsAfter90Days
        enabled: true
        type: Lifecycle
        definition:
          actions:
            delete:
              daysAfterModificationGreaterThan: 90
          filters:
            blobTypes:
              - blockBlob
            prefixMatch:
              - log-storage  # Apply to the existing 'log-storage' container
  providerConfigRef:
    name: azure-config  # Ensure this references the correct Azure credentials
2. Deploy the Lifecycle Policy Using ArgoCD
Add the lifecycle policy YAML file (log-storage-lifecycle-policy.yaml) to your GitOps repo under the appropriate directory:
azure-gitops/
├── storage/
│   ├── resource-group1/
│   │   ├── log-storage-lifecycle-policy.yaml  # Only defining the policy, not the container
│   ├── kustomization.yaml
Modify the kustomization.yaml to include the new policy:
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - resource-group1/log-storage-lifecycle-policy.yaml
Push the changes to your Git repo and let ArgoCD sync.
Manually trigger sync (optional):
argocd app sync azure-storage-gitops
3. Verify the Lifecycle Policy is Applied

Once the policy is deployed, confirm it in Azure:

Using Azure CLI
az storage account management-policy show \
    --account-name <STORAGE_ACCOUNT_NAME> \
    --resource-group <RESOURCE_GROUP>
Using Azure Portal
Navigate to Storage Accounts in Azure.
Select the Storage Account where log-storage exists.
Go to Data management → Lifecycle Management.
You should see the DeleteBlobsAfter90Days policy applied.




#!/bin/bash

# Azure Storage Account Lifecycle Policy Management with ArgoCD

# Step 1: Create Azure Service Principal
echo "Creating Azure Service Principal..."
az login

# Create service principal with Contributor role
az ad sp create-for-rbac \
 --name "argocd-azure-mgmt" \
 --role "Contributor" \
 --scopes /subscriptions/<subscription-id>

# Step 2: Store credentials in OpenShift secret
echo "Creating secret in OpenShift..."
cat << EOF > azure-credentials-secret.yaml
apiVersion: v1
kind: Secret
metadata:
 name: azure-credentials
 namespace: openshift-gitops
type: Opaque
stringData:
 AZURE_TENANT_ID: "<tenant-id>"
 AZURE_CLIENT_ID: "<client-id>"
 AZURE_CLIENT_SECRET: "<client-secret>"
 AZURE_SUBSCRIPTION_ID: "<subscription-id>"
EOF

oc apply -f azure-credentials-secret.yaml

# Step 3: Install Azure Service Operator
echo "Installing Azure Service Operator..."
cat << EOF > azure-operator.yaml
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
 name: azure-service-operator
 namespace: openshift-operators
spec:
 channel: alpha
 installPlanApproval: Automatic
 name: azure-service-operator
 source: community-operators
 sourceNamespace: openshift-marketplace
EOF

oc apply -f azure-operator.yaml

# Step 4: Configure Azure Service Operator
echo "Configuring Azure Service Operator..."
cat << EOF > azure-config.yaml
apiVersion: azure.microsoft.com/v1alpha1
kind: AzureConfig
metadata:
 name: aso-config
 namespace: openshift-operators
spec:
 location: eastus
 resourceGroup: aso-resources
 credentials:
   secretRef:
     name: azure-credentials
     namespace: openshift-gitops
EOF

oc apply -f azure-config.yaml

# Step 5: Create GitOps repository structure
echo "Creating GitOps repository structure..."
mkdir -p azure-gitops-repo/base
mkdir -p azure-gitops-repo/overlays/resource-group-1
mkdir -p azure-gitops-repo/overlays/resource-group-2
mkdir -p azure-gitops-repo/overlays/resource-group-3

# Step 6: Create base lifecycle policy
cat << EOF > azure-gitops-repo/base/storage-lifecycle-policy.yaml
apiVersion: azure.microsoft.com/v1alpha1
kind: StorageAccount
metadata:
 name: storage-account-template
spec:
 location: eastus
 resourceGroup: placeholder
 sku:
   name: Standard_LRS
 kind: StorageV2
 properties:
   accessTier: Hot
   supportsHttpsTrafficOnly: true
   isHnsEnabled: false
 managementPolicies:
   rules:
   - name: delete-old-blobs
     enabled: true
     type: Lifecycle
     definition:
       filters:
         blobTypes:
         - blockBlob
         prefixMatch:
         - logs/
       actions:
         baseBlob:
           delete:
             daysAfterModificationGreaterThan: 90
EOF

# Step 7: Create base kustomization file
cat << EOF > azure-gitops-repo/base/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
- storage-lifecycle-policy.yaml
EOF

# Step 8: Create overlays for each resource group
for rg in 1 2 3; do
 cat << EOF > azure-gitops-repo/overlays/resource-group-$rg/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
- ../../base
patchesStrategicMerge:
- storage-account-patch.yaml
EOF

 cat << EOF > azure-gitops-repo/overlays/resource-group-$rg/storage-account-patch.yaml
apiVersion: azure.microsoft.com/v1alpha1
kind: StorageAccount
metadata:
 name: storage-account-rg$rg
spec:
 resourceGroup: resource-group-$rg
EOF
done

# Step 9: Create ArgoCD applications
echo "Creating ArgoCD applications..."
for rg in 1 2 3; do
 cat << EOF > azure-storage-rg$rg-app.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
 name: azure-storage-rg$rg
 namespace: openshift-gitops
spec:
 project: default
 source:
   repoURL: https://github.com/yourusername/azure-gitops-repo.git
   targetRevision: HEAD
   path: overlays/resource-group-$rg
 destination:
   server: https://kubernetes.default.svc
   namespace: openshift-gitops
 syncPolicy:
   automated:
     prune: true
     selfHeal: true
 ignoreDifferences:
 - group: azure.microsoft.com
   kind: StorageAccount
   jsonPointers:
   - /status
EOF

 oc apply -f azure-storage-rg$rg-app.yaml
done

# Step 10: Create container management job
echo "Creating container management job..."
cat << EOF > create-logs-container-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
 name: create-logs-container
 namespace: openshift-gitops
spec:
 template:
   spec:
     containers:
     - name: azure-cli
       image: mcr.microsoft.com/azure-cli
       command: ["/bin/bash", "-c"]
       args:
       - |
         for rg in 1 2 3; do
           az login --service-principal -u \$AZURE_CLIENT_ID -p \$AZURE_CLIENT_SECRET --tenant \$AZURE_TENANT_ID
           az storage container create --name logs --account-name storage-account-rg\$rg --resource-group resource-group-\$rg
         done
       env:
       - name: AZURE_CLIENT_ID
         valueFrom:
           secretKeyRef:
             name: azure-credentials
             key: AZURE_CLIENT_ID
       - name: AZURE_CLIENT_SECRET
         valueFrom:
           secretKeyRef:
             name: azure-credentials
             key: AZURE_CLIENT_SECRET
       - name: AZURE_TENANT_ID
         valueFrom:
           secretKeyRef:
             name: azure-credentials
             key: AZURE_TENANT_ID
     restartPolicy: Never
 backoffLimit: 4
EOF

oc apply -f create-logs-container-job.yaml

echo "Setup complete. Verify the resources in OpenShift and Azure."







apiVersion: batch/v1
kind: CronJob
metadata:
  name: azure-lifecycle-policy
  namespace: openshift-gitops
spec:
  schedule: "0 0 * * *"  # Runs every day at midnight
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: azure-lifecycle-sa
          containers:
          - name: azure-cli
            image: mcr.microsoft.com/azure-cli
            command: ["/bin/bash", "-c"]
            args:
            - |
              set -e  # Exit on failure

              echo "Fetching list of clusters..."
              CLUSTERS=$(oc get secrets -n openshift-gitops -l cluster-credential=true -o jsonpath='{.items[*].metadata.name}' | tr ' ' '\n')

              for CLUSTER_SECRET in $CLUSTERS; do
                CLUSTER_NAME=$(echo "$CLUSTER_SECRET" | sed 's/^cluster-//')

                echo "Processing cluster: $CLUSTER_NAME"

                # Fetch OpenShift login credentials
                API_URL=$(oc get secret $CLUSTER_SECRET -n openshift-gitops -o jsonpath='{.data.api-url}' | base64 -d)
                TOKEN=$(oc get secret $CLUSTER_SECRET -n openshift-gitops -o jsonpath='{.data.token}' | base64 -d)

                if [ -z "$API_URL" ] || [ -z "$TOKEN" ]; then
                  echo "Missing API URL or token for cluster $CLUSTER_NAME, skipping..."
                  continue
                fi

                # Login to OpenShift cluster
                echo "Logging into OpenShift Cluster: $CLUSTER_NAME..."
                oc login --token="$TOKEN" --server="$API_URL" --insecure-skip-tls-verify=true

                if [ $? -ne 0 ]; then
                  echo "Failed to log into OpenShift Cluster: $CLUSTER_NAME, skipping..."
                  continue
                fi

                # Fetch correct Azure credentials for this cluster
                AZURE_TENANT_ID=$(oc get secret azure-credentials-$CLUSTER_NAME -n openshift-gitops -o jsonpath='{.data.azure_tenant_id}' | base64 -d)
                AZURE_CLIENT_ID=$(oc get secret azure-credentials-$CLUSTER_NAME -n openshift-gitops -o jsonpath='{.data.azure_client_id}' | base64 -d)
                AZURE_CLIENT_SECRET=$(oc get secret azure-credentials-$CLUSTER_NAME -n openshift-gitops -o jsonpath='{.data.azure_client_secret}' | base64 -d)

                if [ -z "$AZURE_TENANT_ID" ] || [ -z "$AZURE_CLIENT_ID" ] || [ -z "$AZURE_CLIENT_SECRET" ]; then
                  echo "Missing Azure credentials for cluster $CLUSTER_NAME, skipping..."
                  continue
                fi

                # Login to Azure using cluster-specific credentials
                echo "Logging into Azure for Cluster: $CLUSTER_NAME..."
                az login --service-principal \
                  --username "$AZURE_CLIENT_ID" \
                  --password "$AZURE_CLIENT_SECRET" \
                  --tenant "$AZURE_TENANT_ID"

                if [ $? -ne 0 ]; then
                  echo "Azure login failed for Cluster: $CLUSTER_NAME, skipping..."
                  continue
                fi

                # Create lifecycle policy JSON
                cat > policy.json << 'EOFPOLICY'
                {
                  "rules": [
                    {
                      "name": "delete-old-blobs",
                      "enabled": true,
                      "type": "Lifecycle",
                      "definition": {
                        "filters": {
                          "blobTypes": ["blockBlob"],
                          "prefixMatch": ["logs/"]
                        },
                        "actions": {
                          "baseBlob": {
                            "delete": {
                              "daysAfterModificationGreaterThan": 90
                            }
                          }
                        }
                      }
                    }
                  ]
                }
                EOFPOLICY

                # Discover storage accounts in this cluster
                echo "Discovering storage accounts for Cluster: $CLUSTER_NAME..."
                STORAGE_ACCOUNTS=$(az storage account list --query "[?tags.RequiresLifecyclePolicy=='true' || starts_with(name,'prod')].[name,resourceGroup]" -o tsv)

                if [ -z "$STORAGE_ACCOUNTS" ]; then
                  echo "No storage accounts found in Cluster: $CLUSTER_NAME"
                  continue
                fi

                # Apply policies in parallel
                echo "$STORAGE_ACCOUNTS" | while read -r ACCOUNT_INFO; do
                  (
                    ACCOUNT_NAME=$(echo "$ACCOUNT_INFO" | awk '{print $1}')
                    RESOURCE_GROUP=$(echo "$ACCOUNT_INFO" | awk '{print $2}')
                    echo "Applying lifecycle policy to $ACCOUNT_NAME in $RESOURCE_GROUP..."

                    az storage account management-policy create \
                      --account-name "$ACCOUNT_NAME" \
                      --resource-group "$RESOURCE_GROUP" \
                      --policy policy.json

                    if [ $? -eq 0 ]; then
                      echo "Successfully applied policy to $ACCOUNT_NAME"
                    else
                      echo "Failed to apply policy to $ACCOUNT_NAME"
                    fi
                  ) &
                done

                wait  # Wait for all background jobs to complete
              done

              echo "Policy application completed for all clusters."
          restartPolicy: Never






====================================================================================
🚀 Step-by-Step Guide: OpenShift Job for Azure Lifecycle Policy with oc & az

This guide ensures that: ✅ The OpenShift CLI (oc) is installed dynamically inside the Azure CLI container.
✅ The Job automatically logs into OpenShift & Azure per cluster.
✅ The Azure Storage lifecycle policy is applied across clusters.
✅ The Job auto-deletes after execution.

Step 1: Create a ServiceAccount with Required Permissions

The Job needs access to:

Read OpenShift cluster secrets (to retrieve API URLs & tokens).
Apply Azure storage lifecycle policies.
Save this as azure-lifecycle-sa.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: azure-lifecycle-sa
  namespace: openshift-gitops
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: azure-lifecycle-role
  namespace: openshift-gitops
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: azure-lifecycle-rolebinding
  namespace: openshift-gitops
subjects:
  - kind: ServiceAccount
    name: azure-lifecycle-sa
    namespace: openshift-gitops
roleRef:
  kind: Role
  name: azure-lifecycle-role
  apiGroup: rbac.authorization.k8s.io
Apply the ServiceAccount
oc apply -f azure-lifecycle-sa.yaml
Step 2: Deploy the One-Time OpenShift Job

This Job will:

Detect OpenShift clusters dynamically.
Install oc inside the Azure CLI container (since oc is not pre-installed).
Extract Azure credentials per cluster.
Apply lifecycle policies to Azure storage accounts.
Automatically delete itself after execution.
Save this as azure-lifecycle-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: azure-lifecycle-apply
  namespace: openshift-gitops
spec:
  ttlSecondsAfterFinished: 600  # Deletes the job 10 minutes after completion
  template:
    spec:
      serviceAccountName: azure-lifecycle-sa
      restartPolicy: Never
      containers:
      - name: azure-cli
        image: mcr.microsoft.com/azure-cli
        command: ["/bin/bash", "-c"]
        args:
        - |
          set -e  # Exit on error

          # Install OpenShift CLI dynamically
          echo "Installing OpenShift CLI..."
          curl -L https://mirror.openshift.com/pub/openshift-v4/clients/oc/latest/linux/oc.tar.gz | tar -xz
          mv oc /usr/local/bin/ && chmod +x /usr/local/bin/oc

          # Verify oc CLI installation
          oc version || { echo "oc CLI installation failed!"; exit 1; }

          echo "Fetching list of clusters..."
          CLUSTERS=$(oc get secrets -n openshift-gitops -l cluster-credential=true -o jsonpath='{.items[*].metadata.name}' | tr ' ' '\n')

          for CLUSTER_SECRET in $CLUSTERS; do
            CLUSTER_NAME=$(echo "$CLUSTER_SECRET" | sed 's/^cluster-//')

            echo "Processing cluster: $CLUSTER_NAME"

            # Fetch OpenShift login credentials
            API_URL=$(oc get secret $CLUSTER_SECRET -n openshift-gitops -o jsonpath='{.data.api-url}' | base64 -d)
            TOKEN=$(oc get secret $CLUSTER_SECRET -n openshift-gitops -o jsonpath='{.data.token}' | base64 -d)

            if [[ -z "$API_URL" || -z "$TOKEN" ]]; then
              echo "Missing API URL or token for cluster $CLUSTER_NAME, skipping..."
              continue
            fi

            # Login to OpenShift cluster
            echo "Logging into OpenShift Cluster: $CLUSTER_NAME..."
            oc login --token="$TOKEN" --server="$API_URL" --insecure-skip-tls-verify=true

            if [[ $? -ne 0 ]]; then
              echo "Failed to log into OpenShift Cluster: $CLUSTER_NAME, skipping..."
              continue
            fi

            # Fetch Azure credentials for this cluster
            AZURE_TENANT_ID=$(oc get secret azure-credentials-$CLUSTER_NAME -n openshift-gitops -o jsonpath='{.data.azure_tenant_id}' | base64 -d)
            AZURE_CLIENT_ID=$(oc get secret azure-credentials-$CLUSTER_NAME -n openshift-gitops -o jsonpath='{.data.azure_client_id}' | base64 -d)
            AZURE_CLIENT_SECRET=$(oc get secret azure-credentials-$CLUSTER_NAME -n openshift-gitops -o jsonpath='{.data.azure_client_secret}' | base64 -d)

            if [[ -z "$AZURE_TENANT_ID" || -z "$AZURE_CLIENT_ID" || -z "$AZURE_CLIENT_SECRET" ]]; then
              echo "Missing Azure credentials for cluster $CLUSTER_NAME, skipping..."
              continue
            fi

            # Login to Azure
            echo "Logging into Azure for Cluster: $CLUSTER_NAME..."
            az login --service-principal \
              --username "$AZURE_CLIENT_ID" \
              --password "$AZURE_CLIENT_SECRET" \
              --tenant "$AZURE_TENANT_ID"

            if [[ $? -ne 0 ]]; then
              echo "Azure login failed for Cluster: $CLUSTER_NAME, skipping..."
              continue
            fi

            # Create lifecycle policy JSON
            cat > policy.json << 'EOFPOLICY'
            {
              "rules": [
                {
                  "name": "delete-old-blobs",
                  "enabled": true,
                  "type": "Lifecycle",
                  "definition": {
                    "filters": {
                      "blobTypes": ["blockBlob"],
                      "prefixMatch": ["logs/"]
                    },
                    "actions": {
                      "baseBlob": {
                        "delete": {
                          "daysAfterModificationGreaterThan": 90
                        }
                      }
                    }
                  }
                }
              ]
            }
            EOFPOLICY

            # Discover storage accounts in this cluster
            echo "Discovering storage accounts for Cluster: $CLUSTER_NAME..."
            STORAGE_ACCOUNTS=$(az storage account list --query "[?tags.RequiresLifecyclePolicy=='true' || starts_with(name,'prod')].[name,resourceGroup]" -o tsv)

            if [[ -z "$STORAGE_ACCOUNTS" ]]; then
              echo "No storage accounts found in Cluster: $CLUSTER_NAME"
              continue
            fi

            # Apply policies in parallel
            echo "$STORAGE_ACCOUNTS" | while read -r ACCOUNT_INFO; do
              (
                ACCOUNT_NAME=$(echo "$ACCOUNT_INFO" | awk '{print $1}')
                RESOURCE_GROUP=$(echo "$ACCOUNT_INFO" | awk '{print $2}')
                echo "Applying lifecycle policy to $ACCOUNT_NAME in $RESOURCE_GROUP..."

                az storage account management-policy create \
                  --account-name "$ACCOUNT_NAME" \
                  --resource-group "$RESOURCE_GROUP" \
                  --policy policy.json

                if [[ $? -eq 0 ]]; then
                  echo "Successfully applied policy to $ACCOUNT_NAME"
                else
                  echo "Failed to apply policy to $ACCOUNT_NAME"
                fi
              ) &
            done

            wait  # Wait for all background jobs to complete
          done

          echo "Policy application completed for all clusters."
Step 3: Deploy the One-Time Job

Run:

oc apply -f azure-lifecycle-job.yaml
Step 4: Monitor Execution

Check Job Status
oc get jobs -n openshift-gitops
View Logs from the Job
oc logs -l job-name=azure-lifecycle-apply -n openshift-gitops


