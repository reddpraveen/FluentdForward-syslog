#!/bin/bash

# 1. Create the bucket replication configuration with existing secrets
cat <<'EOF' > bucket-replication-large.yaml
apiVersion: replication.storage.openshift.io/v1alpha1
kind: BucketReplication
metadata:
  name: mcg-to-rgw-replication
  namespace: openshift-storage
spec:
  source:
    bucketName: mcg-source
    provider:
      type: mcg
      mcg:
        bucketClass: noobaa-default-bucket-class
        secret:
          name: logging-loki-odf
          namespace: openshift-logging
  destination:
    bucketName: rgw-destination
    provider:
      type: rgw
      rgw:
        storageClassName: ocs-storagecluster-ceph-rgw
        secret:
          name: logging-loki-rgw
          namespace: openshift-logging
  rules:
    - prefix: ""
      enabled: true
      syncDeletes: true
      priority: high
  scheduling:
    replicationTime:
      time: 15m
    metrics:
      syncTime: 15m
  performance:
    maxConcurrentRequests: 100
    maxBandwidthUtilization: "50Mi"
  resources:
    limits:
      cpu: "4"
      memory: "8Gi"
    requests:
      cpu: "2"
      memory: "4Gi"
EOF

# 2. Create verification script to check secrets and buckets
cat <<'EOF' > verify-setup.sh
#!/bin/bash

echo "=== Verifying Configuration Setup ==="

echo -e "\n1. Checking Source Secret (logging-loki-odf)..."
oc get secret logging-loki-odf -n openshift-logging &> /dev/null
if [ $? -eq 0 ]; then
    echo "✓ Source secret exists"
else
    echo "✗ Source secret not found"
fi

echo -e "\n2. Checking Target Secret (logging-loki-rgw)..."
oc get secret logging-loki-rgw -n openshift-logging &> /dev/null
if [ $? -eq 0 ]; then
    echo "✓ Target secret exists"
else
    echo "✗ Target secret not found"
fi

echo -e "\n3. Checking NooBaa System Status..."
oc get noobaa -n openshift-storage -o jsonpath='{.status.phase}'

echo -e "\n4. Checking RGW Status..."
oc get cephobjectstore -n openshift-storage

echo "=== Verification Complete ==="
EOF

# 3. Create monitoring script
cat <<'EOF' > monitor-replication.sh
#!/bin/bash

while true; do
    clear
    echo "=== Replication Status Check $(date) ==="
    
    echo -e "\n1. Replication Health Status:"
    oc get bucketreplication mcg-to-rgw-replication -n openshift-storage -o jsonpath='{.status.health}'
    
    echo -e "\n\n2. Data Transfer Progress:"
    oc get bucketreplication mcg-to-rgw-replication -n openshift-storage -o jsonpath='{.status.metrics.bytesTransferred}'
    
    echo -e "\n\n3. Recent Events:"
    oc get events -n openshift-storage --field-selector reason=BucketReplication --sort-by='.lastTimestamp' | tail -n 5
    
    echo -e "\n\n4. Pod Resource Usage:"
    oc adm top pod -n openshift-storage | grep -E 'noobaa|rgw'
    
    echo -e "\n----------------------------------------"
    sleep 300  # Update every 5 minutes
done
EOF

# 4. Create recovery script
cat <<'EOF' > replication-recovery.sh
#!/bin/bash

check_health() {
    oc get bucketreplication mcg-to-rgw-replication -n openshift-storage -o jsonpath='{.status.health}'
}

restart_replication() {
    echo "$(date): Attempting replication restart..."
    oc patch bucketreplication mcg-to-rgw-replication -n openshift-storage --type=merge \
        -p '{"spec":{"rules":[{"enabled":false}]}}'
    sleep 10
    oc patch bucketreplication mcg-to-rgw-replication -n openshift-storage --type=merge \
        -p '{"spec":{"rules":[{"enabled":true}]}}'
    echo "Replication restarted. Monitoring health..."
}

while true; do
    health=$(check_health)
    if [[ "$health" != "Healthy" ]]; then
        echo "$(date): Unhealthy replication detected"
        restart_replication
    fi
    sleep 600
done
EOF

# Make scripts executable
chmod +x verify-setup.sh monitor-replication.sh replication-recovery.sh

# Create README with instructions
cat <<'EOF' > README.md
ODF 4.14 Large Data Replication Guide
====================================

Prerequisites:
-------------
- Existing secrets in openshift-logging namespace:
  - logging-loki-odf (source)
  - logging-loki-rgw (target)
- Existing buckets configured

Setup Steps:
-----------
1. Verify configuration:
   ./verify-setup.sh

2. Start replication:
   oc apply -f bucket-replication-large.yaml

Monitoring:
----------
1. Monitor replication:
   ./monitor-replication.sh

2. Auto-recovery (optional):
   ./replication-recovery.sh

Useful Commands:
--------------
1. Check replication status:
   oc get bucketreplication mcg-to-rgw-replication -n openshift-storage

2. View replication metrics:
   oc get bucketreplication mcg-to-rgw-replication -n openshift-storage -o jsonpath='{.status.metrics}'

3. Check for errors:
   oc get events -n openshift-storage --field-selector reason=BucketReplication

Control Commands:
---------------
1. Pause replication:
   oc patch bucketreplication mcg-to-rgw-replication -n openshift-storage --type=merge \
     -p '{"spec":{"rules":[{"enabled":false}]}}'

2. Resume replication:
   oc patch bucketreplication mcg-to-rgw-replication -n openshift-storage --type=merge \
     -p '{"spec":{"rules":[{"enabled":true}]}}'

Notes:
-----
- Using existing secrets from openshift-logging namespace
- Expected completion time for 125GB: 2-4 hours under normal conditions
- Monitor storage capacity regularly
- Check system resources during replication
EOF

echo "All configuration files and scripts have been created."
echo "Please read README.md for detailed instructions."











=======================================================================
# Save this as odf-bucket-replication.sh

#!/bin/bash
# ODF 4.14 Bucket Replication Setup Guide
# This script contains commands for setting up bucket replication between MCG and RGW

# Step 1: Verify Environment
echo "Checking ODF version and status..."
oc get csv -n openshift-storage | grep ocs-operator
oc get storagecluster -n openshift-storage
oc get pods -n openshift-storage | grep -E 'noobaa|rgw'

# Step 2: Create source bucket (MCG)
cat <<'EOF' > mcg-source-bucket.yaml
apiVersion: objectbucket.io/v1alpha1
kind: ObjectBucketClaim
metadata:
  name: mcg-source-bucket
  namespace: openshift-storage
spec:
  generateBucketName: mcg-source
  storageClassName: noobaa.noobaa.io
  additionalConfig:
    bucketclass: noobaa-default-bucket-class
EOF

# Step 3: Create destination bucket (RGW)
cat <<'EOF' > rgw-destination-bucket.yaml
apiVersion: objectbucket.io/v1alpha1
kind: ObjectBucketClaim
metadata:
  name: rgw-destination-bucket
  namespace: openshift-storage
spec:
  generateBucketName: rgw-destination
  storageClassName: ocs-storagecluster-ceph-rgw
EOF

# Step 4: Create bucket replication policy
cat <<'EOF' > bucket-replication.yaml
apiVersion: replication.storage.openshift.io/v1alpha1
kind: BucketReplication
metadata:
  name: mcg-to-rgw-replication
  namespace: openshift-storage
spec:
  source:
    bucketName: mcg-source
    provider:
      type: mcg
      mcg:
        bucketClass: noobaa-default-bucket-class
  destination:
    bucketName: rgw-destination
    provider:
      type: rgw
      rgw:
        storageClassName: ocs-storagecluster-ceph-rgw
  rules:
    - prefix: ""
      enabled: true
      syncDeletes: true
  scheduling:
    replicationTime:
      time: 15m
    metrics:
      syncTime: 15m
EOF

# Optional: Create secure bucket class
cat <<'EOF' > secure-bucket-class.yaml
apiVersion: noobaa.io/v1alpha1
kind: BucketClass
metadata:
  name: secure-bucket-class
  namespace: openshift-storage
spec:
  placementPolicy:
    tiers:
    - placement: "Spread"
      backingStores:
      - noobaa-default-backing-store
  encryption:
    enable: true
EOF

# Save these commands as verify-commands.sh
cat <<'EOF' > verify-commands.sh
#!/bin/bash

# Apply configurations
echo "Applying configurations..."
oc apply -f mcg-source-bucket.yaml
oc apply -f rgw-destination-bucket.yaml
oc apply -f bucket-replication.yaml

# Verify setup
echo "Verifying bucket claims..."
oc get objectbucketclaim -n openshift-storage

echo "Checking replication status..."
oc get bucketreplication -n openshift-storage

echo "Getting detailed replication status..."
oc describe bucketreplication mcg-to-rgw-replication -n openshift-storage

# Get access credentials
echo "Getting MCG source bucket credentials..."
echo "AWS_ACCESS_KEY_ID:"
oc get secret mcg-source-bucket -n openshift-storage -o jsonpath='{.data.AWS_ACCESS_KEY_ID}' | base64 -d
echo
echo "AWS_SECRET_ACCESS_KEY:"
oc get secret mcg-source-bucket -n openshift-storage -o jsonpath='{.data.AWS_SECRET_ACCESS_KEY}' | base64 -d
echo

echo "Getting RGW destination bucket credentials..."
echo "AWS_ACCESS_KEY_ID:"
oc get secret rgw-destination-bucket -n openshift-storage -o jsonpath='{.data.AWS_ACCESS_KEY_ID}' | base64 -d
echo
echo "AWS_SECRET_ACCESS_KEY:"
oc get secret rgw-destination-bucket -n openshift-storage -o jsonpath='{.data.AWS_SECRET_ACCESS_KEY}' | base64 -d
echo

# Get endpoints
echo "Getting MCG endpoint..."
oc get route s3 -n openshift-storage -o jsonpath='{.spec.host}'
echo

echo "Getting RGW endpoint..."
oc get route s3-rgw -n openshift-storage -o jsonpath='{.spec.host}'
echo
EOF

# Save monitoring commands as monitor-replication.sh
cat <<'EOF' > monitor-replication.sh
#!/bin/bash

echo "Checking MCG operator logs..."
oc logs -n openshift-storage deployment/noobaa-operator

echo "Checking RGW logs..."
oc logs -n openshift-storage deployment/ocs-storagecluster-cephrgw

echo "Getting replication events..."
oc get events -n openshift-storage --field-selector reason=BucketReplication

echo "Checking NooBaa system status..."
oc get noobaa -n openshift-storage -o yaml

echo "Checking replication metrics..."
oc get bucketreplication mcg-to-rgw-replication -o jsonpath='{.status.metrics}' -n openshift-storage
EOF

# Save cleanup commands as cleanup.sh
cat <<'EOF' > cleanup.sh
#!/bin/bash

echo "Deleting replication..."
oc delete bucketreplication mcg-to-rgw-replication -n openshift-storage

echo "Deleting bucket claims..."
oc delete objectbucketclaim mcg-source-bucket -n openshift-storage
oc delete objectbucketclaim rgw-destination-bucket -n openshift-storage
EOF

# Make scripts executable
chmod +x verify-commands.sh monitor-replication.sh cleanup.sh
